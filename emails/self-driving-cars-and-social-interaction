I've been thinking out loud about self-driving cars [for a few years now][ws], but two articles by Rodney Brooks highlighted a number of concerns that have actually never occurred to me before:

- [Unexpected Consequences of Self-Driving Cars][consequences]
- [Edge Cases for Self-Driving Cars][edge cases]

[consequences]: http://rodneybrooks.com/unexpected-consequences-of-self-driving-cars/
[edge cases]: http://rodneybrooks.com/edge-cases-for-self-driving-cars/

Lots of people talk about edge cases for self-driving cars—but Brooks’ discussion is substantially more *interesting* than most of those… like: when is it appropriate for an autonomous vehicle to *honk*, or for people to honk *at* an autonomous vehicle?

[ws]: https://winningslowly.org/3.13/

People often work off of subtle non-verbal cues that drivers send: we can tell that a car is apt to switch lanes based on the little ways the vehicles drift and the way we interpret the driver’s (barely-visible! But we still use it) body language. We recognize and expect certain kinds of behavior from drivers we intuit to fit into certain categories: inexperienced, not-from-around-here, aging, impatient, distracted, and so on.

Self-driving cars have none of those. They’ll have their own cues, and we’ll come to recognize and respond to them; but they will both be very different from the ones we are accustomed to and they will not (for a very long time, at least) be able to carry on the completely non-verbal two-way dialogue that happens between a pair of drivers, or between a driver and a bicyclist, or between a driver and a pedestrian…

There's a lot here, and Brooks’ articles are not alarmist in the least, but *realist* in the best sense: careful and thorough and accurate. So, give them a read:

- [Unexpected Consequences of Self-Driving Cars][consequences]
- [Edge Cases for Self-Driving Cars][edge cases]